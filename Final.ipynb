{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa274de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession .builder.appName(\"final_assignment\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e004fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('TRANS_SRC_XLSX.csv', header = True , inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7810aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TRANSACTION_ID',\n",
       " 'TRANSACTION_DATE',\n",
       " 'USER_FULL_NAME',\n",
       " 'GENDER',\n",
       " 'EMAIL_CONTACT',\n",
       " 'PRODUCT_DESCRIPTION',\n",
       " 'PRODUCT_UNIT_PRICE',\n",
       " 'QUANTITY',\n",
       " 'DISCOUNT_AMOUNT',\n",
       " 'NET_SALE_VALUE',\n",
       " 'REGION',\n",
       " 'COUNTRY',\n",
       " 'CAPITAL_CITY',\n",
       " 'EVENT_LOG_TIMESTAMP']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5153cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TRANSACTION_ID: double (nullable = true)\n",
      " |-- TRANSACTION_DATE: string (nullable = true)\n",
      " |-- USER_FULL_NAME: string (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- EMAIL_CONTACT: string (nullable = true)\n",
      " |-- PRODUCT_DESCRIPTION: string (nullable = true)\n",
      " |-- PRODUCT_UNIT_PRICE: integer (nullable = true)\n",
      " |-- QUANTITY: integer (nullable = true)\n",
      " |-- DISCOUNT_AMOUNT: integer (nullable = true)\n",
      " |-- NET_SALE_VALUE: integer (nullable = true)\n",
      " |-- REGION: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- CAPITAL_CITY: string (nullable = true)\n",
      " |-- EVENT_LOG_TIMESTAMP: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de78d360",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:powderblue; text-align:center;\"> First Task : Remove NULL values and store rows in Junk df </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32f8fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter1 = df.dropna('any')\n",
    "df_junk = df.subtract(df_filter1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd5247",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:powderblue; text-align:center;\">Second Task : Email Validation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9baa282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083d7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_filter1.withColumn('matched',when(df_filter1.EMAIL_CONTACT.rlike('^\\w+([\\.-]?\\w+)*@\\w+([\\.-]?\\w+)*(\\.\\w{2,3})+$'),True).otherwise(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f597614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_email_df = df_test.filter(df_test.matched == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11978407",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_email_df = valid_email_df.drop('matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4707cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_email_df = df_test.filter(df_test.matched == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "978421da",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_email_df_update = invalid_email_df.drop('matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d686a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_updated=df_junk.unionByName(invalid_email_df_update, allowMissingColumns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ae93cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9317"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "junk_updated.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee94550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------+------+--------------------+-------------------+------------------+--------+---------------+--------------+--------------------+---------+------------+--------------------+\n",
      "|TRANSACTION_ID|    TRANSACTION_DATE|USER_FULL_NAME|GENDER|       EMAIL_CONTACT|PRODUCT_DESCRIPTION|PRODUCT_UNIT_PRICE|QUANTITY|DISCOUNT_AMOUNT|NET_SALE_VALUE|              REGION|  COUNTRY|CAPITAL_CITY| EVENT_LOG_TIMESTAMP|\n",
      "+--------------+--------------------+--------------+------+--------------------+-------------------+------------------+--------+---------------+--------------+--------------------+---------+------------+--------------------+\n",
      "|    1.46493E12|2016-Jun-05 10:29:43|          null|  null|         H@gmail.com|         ELECTRICAL|               250|       1|              7|           243|WESTERN EUROPE   ...| Belgium |    Brussels|2016-Jun-03 10:29:43|\n",
      "|    1.46493E12|2016-Jun-06 10:32:07|          null|  null|w.william.f.ford@...|               ARTS|                35|       4|              9|           131|LATIN AMER. & CAR...| Ecuador |       Quito|2016-Jun-03 10:32:07|\n",
      "|    1.46493E12|2016-Jun-06 10:32:16|          null|  null|         B@gmail.com|              GAMES|               100|       5|              6|           494|ASIA (EX. NEAR EA...|Cambodia |  Phnom Penh|2016-Jun-03 10:32:16|\n",
      "|    1.46493E12|2016-Jun-07 10:37:07|          null|  null|         H@gmail.com|              GAMES|               100|       7|              9|           691|LATIN AMER. & CAR...| Ecuador |       Quito|2016-Jun-03 10:37:07|\n",
      "|    1.46493E12|2016-Jun-07 10:38:05|          null|  null|         F@gmail.com|               ARTS|                35|       8|              4|           276|ASIA (EX. NEAR EA...|    Laos |   Vientiane|2016-Jun-03 10:38:05|\n",
      "+--------------+--------------------+--------------+------+--------------------+-------------------+------------------+--------+---------------+--------------+--------------------+---------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "junk_updated.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff6a504",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:powderblue; text-align:center;\">Third Task : Split Name Column</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31b35a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0a68c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_names = valid_email_df.withColumn(\"First Name\", split(col(\"USER_FULL_NAME\"), \" \").getItem(0)).withColumn(\"Last Name\", split(col(\"USER_FULL_NAME\"), \" \").getItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54fa48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_names = splitted_names.drop('USER_FULL_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b21c2d",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:powderblue; text-align:center;\"> Fourth Task : Validate Gender Column </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d302495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df_gender_modify = splitted_names.withColumn(\"GENDER\", when(splitted_names.GENDER == \"M\",\"MALE\")\n",
    "                    .when(splitted_names.GENDER == \"m\",\"MALE\")\n",
    "                    .when(splitted_names.GENDER == \"male\",\"MALE\")\n",
    "                    .when(splitted_names.GENDER == \"Male\",\"MALE\")\n",
    "                    .when(splitted_names.GENDER == \"f\",\"FEMALE\")\n",
    "                    .when(splitted_names.GENDER == \"F\",\"FEMALE\")\n",
    "                    .when(splitted_names.GENDER == \"Female\",\"FEMALE\")\n",
    "                    .when(splitted_names.GENDER == \"female\",\"FEMALE\")\n",
    "                    .otherwise(splitted_names.GENDER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b9b2d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+------+--------------------+-------------------+------------------+--------+---------------+--------------+--------------------+-------------+------------+--------------------+-----------+---------+\n",
      "|TRANSACTION_ID|    TRANSACTION_DATE|GENDER|       EMAIL_CONTACT|PRODUCT_DESCRIPTION|PRODUCT_UNIT_PRICE|QUANTITY|DISCOUNT_AMOUNT|NET_SALE_VALUE|              REGION|      COUNTRY|CAPITAL_CITY| EVENT_LOG_TIMESTAMP| First Name|Last Name|\n",
      "+--------------+--------------------+------+--------------------+-------------------+------------------+--------+---------------+--------------+--------------------+-------------+------------+--------------------+-----------+---------+\n",
      "|    1.46493E12|2016-Jun-09 10:19:19|  MALE|m.millard.b.bucha...|               ARTS|                35|      10|              9|           341|C.W. OF IND. STATES |Turkmenistan |    Ashgabat|2016-Jun-03 10:19:19| Mr.Millard| Buchanan|\n",
      "|    1.46493E12|2016-Jun-09 10:19:19|FEMALE|       m@hotmail.com|          FURNITURE|               450|       8|              9|          3591|LATIN AMER. & CAR...| Puerto Rico |    San Juan|2016-Jun-03 10:19:19| Mrs.Martin| Coolidge|\n",
      "|    1.46493E12|2016-Jun-06 10:19:20|  MALE|t.theodore.t.tyle...|            CUTLERY|                75|       6|              1|           449|ASIA (EX. NEAR EA...|    Cambodia |  Phnom Penh|2016-Jun-03 10:19:20|Mr.Theodore|    Tyler|\n",
      "+--------------+--------------------+------+--------------------+-------------------+------------------+--------+---------------+--------------+--------------------+-------------+------------+--------------------+-----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gender_modify.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf7426",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:powderblue; text-align:center;\"> Fifth Task : Split dates </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98e62df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month\n",
    "from pyspark.sql.functions import to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "935b99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = df_gender_modify.withColumn(\"TRANSACTION_DATE\",to_date(col(\"TRANSACTION_DATE\"),\"yyyy-LLL-dd HH:mm:ss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7461708",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_df = true_df.withColumn('Year',year(true_df.TRANSACTION_DATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "619e8dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_df = year_df.withColumn('Month',month(year_df.TRANSACTION_DATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "264e1962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofmonth\n",
    "\n",
    "day_df = month_df.withColumn('Day',dayofmonth(month_df.TRANSACTION_DATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46f545dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import weekofyear\n",
    " \n",
    "week_df = day_df.withColumn('Week',weekofyear(day_df.TRANSACTION_DATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "157cc615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import quarter\n",
    "\n",
    "Final = week_df.withColumn('Quarter',quarter(week_df.TRANSACTION_DATE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54041f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7e93ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalDF = Final.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f34bf320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FinalDF.to_csv('final_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f42084a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Junk = junk_updated.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ede8e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Junk.to_csv('junk.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
